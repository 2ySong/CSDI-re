{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(config='base_forecasting.yaml', datatype='electricity', device=device(type='cuda', index=0), seed=1, unconditional=False, modelfolder='', nsample=10)\n",
      "{\n",
      "    \"train\": {\n",
      "        \"epochs\": 20,\n",
      "        \"batch_size\": 8,\n",
      "        \"lr\": 0.001,\n",
      "        \"itr_per_epoch\": 100000000.0\n",
      "    },\n",
      "    \"diffusion\": {\n",
      "        \"layers\": 4,\n",
      "        \"channels\": 64,\n",
      "        \"nheads\": 8,\n",
      "        \"diffusion_embedding_dim\": 128,\n",
      "        \"beta_start\": 0.0001,\n",
      "        \"beta_end\": 0.5,\n",
      "        \"num_steps\": 50,\n",
      "        \"schedule\": \"quad\",\n",
      "        \"is_linear\": true\n",
      "    },\n",
      "    \"model\": {\n",
      "        \"is_unconditional\": false,\n",
      "        \"timeemb\": 128,\n",
      "        \"featureemb\": 16,\n",
      "        \"target_strategy\": \"test\",\n",
      "        \"num_sample_features\": 64\n",
      "    }\n",
      "}\n",
      "model folder: ./models_save/forecasting_electricity_20240623_205238/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSDI_Forecasting(\n",
      "  (embed_layer): Embedding(370, 16)\n",
      "  (diffmodel): diff_CSDI(\n",
      "    (diffusion_embedding): DiffusionEmbedding(\n",
      "      (projection1): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (projection2): Linear(in_features=128, out_features=128, bias=True)\n",
      "    )\n",
      "    (catt): CoordAtt(\n",
      "      (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
      "      (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
      "      (conv1): Conv2d(2, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): h_swish(\n",
      "        (sigmoid): h_sigmoid(\n",
      "          (relu): ReLU6(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (conv_h): Conv2d(8, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (conv_w): Conv2d(8, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (input_projection): Conv1d(2, 64, kernel_size=(1,), stride=(1,))\n",
      "    (output_projection1): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "    (output_projection2): Conv1d(64, 1, kernel_size=(1,), stride=(1,))\n",
      "    (residual_layers): ModuleList(\n",
      "      (0-3): 4 x ResidualBlock(\n",
      "        (diffusion_projection): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (cond_projection): Conv1d(145, 128, kernel_size=(1,), stride=(1,))\n",
      "        (mid_projection): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
      "        (output_projection): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
      "        (time_layer): LinearAttentionTransformer(\n",
      "          (layers): SequentialSequence(\n",
      "            (layers): ModuleList(\n",
      "              (0): ModuleList(\n",
      "                (0): PreNorm(\n",
      "                  (fn): SelfAttention(\n",
      "                    (local_attn): LocalAttention(\n",
      "                      (dropout): Dropout(p=0.0, inplace=False)\n",
      "                    )\n",
      "                    (to_q): Linear(in_features=64, out_features=64, bias=False)\n",
      "                    (to_k): Linear(in_features=64, out_features=64, bias=False)\n",
      "                    (to_v): Linear(in_features=64, out_features=64, bias=False)\n",
      "                    (to_out): Linear(in_features=64, out_features=64, bias=True)\n",
      "                    (dropout): Dropout(p=0.0, inplace=False)\n",
      "                  )\n",
      "                  (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "                )\n",
      "                (1): PreNorm(\n",
      "                  (fn): Chunk(\n",
      "                    (fn): FeedForward(\n",
      "                      (w1): Linear(in_features=64, out_features=256, bias=True)\n",
      "                      (act): GELU(approximate='none')\n",
      "                      (dropout): Dropout(p=0.0, inplace=False)\n",
      "                      (w2): Linear(in_features=256, out_features=64, bias=True)\n",
      "                    )\n",
      "                  )\n",
      "                  (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (feature_layer): LinearAttentionTransformer(\n",
      "          (layers): SequentialSequence(\n",
      "            (layers): ModuleList(\n",
      "              (0): ModuleList(\n",
      "                (0): PreNorm(\n",
      "                  (fn): SelfAttention(\n",
      "                    (local_attn): LocalAttention(\n",
      "                      (dropout): Dropout(p=0.0, inplace=False)\n",
      "                    )\n",
      "                    (to_q): Linear(in_features=64, out_features=64, bias=False)\n",
      "                    (to_k): Linear(in_features=64, out_features=64, bias=False)\n",
      "                    (to_v): Linear(in_features=64, out_features=64, bias=False)\n",
      "                    (to_out): Linear(in_features=64, out_features=64, bias=True)\n",
      "                    (dropout): Dropout(p=0.0, inplace=False)\n",
      "                  )\n",
      "                  (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "                )\n",
      "                (1): PreNorm(\n",
      "                  (fn): Chunk(\n",
      "                    (fn): FeedForward(\n",
      "                      (w1): Linear(in_features=64, out_features=256, bias=True)\n",
      "                      (act): GELU(approximate='none')\n",
      "                      (dropout): Dropout(p=0.0, inplace=False)\n",
      "                      (w2): Linear(in_features=256, out_features=64, bias=True)\n",
      "                    )\n",
      "                  )\n",
      "                  (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 269/691 [00:43<01:08,  6.20it/s, avg_epoch_loss=0.361, epoch=0]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/myDL/Projects1/MyCsdi-Forecasting-2/exe_forecasting.py:71\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28mprint\u001b[39m(model)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mmodelfolder \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 71\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfoldername\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfoldername\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_state_dict(\n\u001b[1;32m     80\u001b[0m         torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./models_save/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m args\u001b[38;5;241m.\u001b[39mmodelfolder \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/model.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     81\u001b[0m     )\n",
      "File \u001b[0;32m~/myDL/Projects1/MyCsdi-Forecasting-2/utils.py:53\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, config, train_loader, valid_loader, valid_epoch_interval, foldername)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# loss.backward()\u001b[39;00m\n\u001b[1;32m     52\u001b[0m accelerator\u001b[38;5;241m.\u001b[39mbackward(loss)\n\u001b[0;32m---> 53\u001b[0m avg_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     55\u001b[0m it\u001b[38;5;241m.\u001b[39mset_postfix(\n\u001b[1;32m     56\u001b[0m     ordered_dict\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavg_epoch_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: avg_loss \u001b[38;5;241m/\u001b[39m batch_no,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     60\u001b[0m     refresh\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     61\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%run exe_forecasting.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
